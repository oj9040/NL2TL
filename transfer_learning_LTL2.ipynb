{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4obJC-T3TUpN","outputId":"039b70d7-a5d2-4130-d972-8897a721e38e","executionInfo":{"status":"ok","timestamp":1732444831475,"user_tz":-540,"elapsed":6708,"user":{"displayName":"Jihun Oh","userId":"16459593472256263899"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipdb\n","  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Collecting portalocker (from sacrebleu)\n","  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n","Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.1.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (75.1.0)\n","Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, portalocker, jedi, fsspec, dill, colorama, sacrebleu, multiprocess, ipdb, datasets, evaluate\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed colorama-0.4.6 datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 ipdb-0.13.13 jedi-0.19.2 multiprocess-0.70.16 portalocker-3.0.0 sacrebleu-2.4.3 xxhash-3.5.0\n"]}],"source":["! pip install datasets transformers nltk evaluate sacrebleu ipdb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bvNguj2sUDJj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732444851297,"user_tz":-540,"elapsed":19826,"user":{"displayName":"Jihun Oh","userId":"16459593472256263899"}},"outputId":"a09afe1a-bdae-42c5-834d-79249d04f9fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mzG0pqYUGBd","executionInfo":{"status":"ok","timestamp":1732444851298,"user_tz":-540,"elapsed":8,"user":{"displayName":"Jihun Oh","userId":"16459593472256263899"}},"outputId":"6a6ad765-adad-490e-e507-1102bb9353bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab_Notebooks/github/NL2TL\n"]}],"source":["%cd /content/drive/MyDrive/Colab_Notebooks/github/NL2TL"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"aiNPkB45Vh8-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732444869808,"user_tz":-540,"elapsed":18516,"user":{"displayName":"Jihun Oh","userId":"16459593472256263899"}},"outputId":"3e99f3a2-9485-4e47-c2fd-0902c7a56317"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["t5-base\n","\n","\n"]}],"source":["import nltk\n","nltk.download('punkt_tab')\n","import transformers\n","\n","from IPython.core import error\n","import json\n","from fnmatch import fnmatchcase as match\n","import random\n","import os\n","import pandas as pd\n","import datasets\n","from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n","import numpy as np\n","from argparse import ArgumentParser\n","from typing import Dict, List, Union\n","import ast\n","import csv\n","import ipdb\n","import ast\n","import evaluate\n","\n","## params\n","int_seed = 1203\n","dataset_name = \"LTL_koreauniv\"\n","init_weight = \"with_pre-train\"\n","data_size = \"0.1-0.9\"\n","model_checkpoint = \"t5-base\"\n","print(model_checkpoint)\n","print('\\n')\n","\n","home_path = \"/content/drive/MyDrive/Colab_Notebooks/github/NL2TL\"\n","data_dir = \"dataset\"\n","data_filename = \"command_LTL_dataset_v01.csv\"\n","data_path = os.path.join(home_path, data_dir, data_filename)\n","\n","symbol_to_word_map = {\n","    \"F(\": \"finally(\",\n","    \"G(\": \"globally(\",\n","    \"U(\": \"until(\",\n","    \"&\": \"and\",\n","    \"¬\": \"not\",\n","    \"∧\": \"and\",\n","    \"∨\": \"or\",\n","    \"→\": \"imply\",\n","}\n","\n","# read original csv\n","with open(data_path, newline='') as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    data = []\n","    for row in reader:\n","        data.append([ast.literal_eval(row[\"generated_command\"]),\n","                        ast.literal_eval(row[\"generated_LTL\"])])\n","\n","# realign dataset format and write to csv\n","new_data_filename = data_filename[:-4] + \"_realign.csv\"\n","f = open(os.path.join(home_path, data_dir, new_data_filename), 'w')\n","csv_writer = csv.writer(f)\n","csv_writer.writerow([\"id\", \"ltl\", \"sentence\"])\n","i = 1\n","for item in data:\n","    sents, ltls = item[0], item[1]\n","    for s in sents:\n","        for l in ltls:\n","            # convert symbol to word\n","            for k, v in symbol_to_word_map.items():\n","                l = l.replace(k, v)\n","            csv_writer.writerow([i, l, s])\n","            i += 1\n","f.close()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244,"referenced_widgets":["d033103e85e3471fba23e9a9cf5b179e","5c061efea6b047898f6931781b9aeedf","e249614be7cb4ed1bbb13e41e70d05de","75d73ad5f38e4c3cb7d5970fc2f17f34","40a95f147e0f4be093bdb7d710fadbd1","f5df7c5d7c954fc49a23008e024ca20b","6b1cb18980b943e6acb4ab794c3f6318","769791cd621a492ab808711536e8e0f1","4cb25a830a7b4fe1ae6cb25a76de32c9","4e42072e5f284e998d29089d75c1ac0a","8a4e89fa1122441d8677422c7c41d1f8","862cda28d31844f9bf38be758a714faa","d5fd87dc614f4ceead7073d9657541ed","3cc0979deafb42ec9040322bf73e2949","ce5dfc9b71584791920a466353ff4b0d","fb89dc78b8a94f65b81a4d68d3df060e","b540cc15830f48a68ad99f56bae86e94","4bcb4bd9728643e2874a9618e3710f23","664c94ce75f94b2788f4760110c617f4","84de81bdfcb443c496cfff3fa00ca4ee","349112816f9945deaae49a27c8e2b293","de69b594557a4968b47b7d00761c1db9","3e020babe48d45f39a4350341521ed53","cf24b16d4fde49a8bff7642b1462c15e","ac1d77834f4c4583a98c2b4797cd54f6","492580da9fb54ad088e670598f4cb4a2","8d01078294694f7395feea9a1a7d7cdd","22fd138d7ba8407fbe8db57e3bfd5513","e27690fdacf141fe9e674f7065e90aa5","266b92d1da8747709735b9f1f3d07bbe","cbdd10b2bc73463d8cfac83ffb084da2","3095935ce58c489f836b43be6c6ce6ba","40a0098398694ffaa8cc6b417ea0ffe9"]},"id":"U_aF_aAhUtw9","outputId":"f06fd43b-3b17-42cc-8b92-d549a9200208","executionInfo":{"status":"ok","timestamp":1732444872868,"user_tz":-540,"elapsed":3062,"user":{"displayName":"Jihun Oh","userId":"16459593472256263899"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d033103e85e3471fba23e9a9cf5b179e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"862cda28d31844f9bf38be758a714faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e020babe48d45f39a4350341521ed53"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","\n","# path\n","input_model_dir = os.path.join(home_path, \"model\", \"t5-base-epch20-infix-word-04-21\", \"checkpoint-62500\")\n","output_model_dir = os.path.join(home_path, \"model\", \"t5-base-transfer-learning/\")\n","if not os.path.exists(output_model_dir):\n","  os.mkdir(output_model_dir)\n","\n","# tokenizer and params\n","tokenizer = AutoTokenizer.from_pretrained(input_model_dir)\n","max_input_length = 1024\n","max_target_length = 128\n","prefix = \"Transform the following sentence into Signal Temporal logic: \"\n","\n","# preprocess data\n","def preprocess_function(examples):\n","    inputs = [prefix + doc for doc in examples[\"sentence\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","    # Setup the tokenizer for targets\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(examples[\"ltl\"], max_length=max_target_length, truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    model_inputs[\"sentence\"] = examples[\"sentence\"]\n","    model_inputs[\"ltl\"] = examples[\"ltl\"]\n","    model_inputs[\"id\"] = examples[\"id\"]\n","    return model_inputs\n","\n","# define compute metrics\n","bleu_metric = evaluate.load(\"bleu\", force_prefix=True)\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    # print(predictions)\n","    # print(labels)\n","    # Replace -100 in the labels as we can't decode them.\n","    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    count = 0\n","\n","    # top-1 accuracy\n","    for i in range(len(decoded_preds)):\n","        pred = nltk.sent_tokenize(decoded_preds[i].strip())\n","        label = nltk.sent_tokenize(decoded_labels[i].strip())\n","        if pred == label:\n","            count += 1\n","\n","    bleu = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    return {'top-1 accuracy': round(count / len(decoded_preds), 6),\n","            'bleu score': bleu['bleu'],\n","            'bleu precisions': bleu['precisions']}\n","\n","# correct parenthesis\n","def correct_parenthe(input_str):\n","  count = 0\n","  original_list = input_str.split(' ')\n","  for index, item in enumerate(original_list):\n","    if len(item) >2:\n","      if item[-1] == '.':\n","        original_list[index] = original_list[index][:-1]\n","    if item == '(':\n","      count += 1\n","    elif item == ')':\n","      count -= 1\n","  if count >0:\n","    for i in range(count):\n","      original_list.append(')')\n","  if count <0:\n","    for i in range(-count):\n","      original_list.pop(-1)\n","  return ' '.join(original_list)"]},{"cell_type":"markdown","metadata":{"id":"NJASL9hlX1KM"},"source":["The below is the training code block. So you would nee to run the below for transfer-learning fit to the specific dataset."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4c298f50562d4c38ab287b02cbf002d3","576c26e73f4c4e9781b637ecc2c57019","d383be59f5374e7aaf15748220d913e6","27d1074151fe48038efbe62718bda78c","548a28cf358d4b4998ab1e0864410e1b","39ee03521db0459aaefd3f9b78808d2c","7167c31aba1544adace00ab9296dc9bd","c07d1c8b91a34b89ac5da66bd7f07dfd","a9db5829ff51494cb489124ba8fb8457","1408aac59cc54428a8273ac15046759b","b75bed6e93b14801abc9dde849664d7a","d382c55a8d41415781d4f9233df58d07","195f425ae5ac40b0bcfdf776966ec432","6e79fc3bd54349c8a851001799f421fa","297c3eed091845c09eabf2c47db3c12a","24653031bda54937b249883fe1d46281","bee8f25e152847e795600bcd61ab94af","8fffaba9808c43c384cd1e3577c68005","ad1af20536084184874b1211ef57fd22","f98c6fd46c9147a4a0f1e94b1a75efbd","0d7ffe69833b46a9a1e04188eb7ae0c9","9c999c7623f54164a63d474c7346c360"]},"id":"gq98tyhnkHiN","outputId":"145864a5-6c1d-4734-9f59-f914de72dd63","executionInfo":{"status":"ok","timestamp":1732447686735,"user_tz":-540,"elapsed":1222489,"user":{"displayName":"Jihun Oh","userId":"16459593472256263899"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1872 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c298f50562d4c38ab287b02cbf002d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/208 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d382c55a8d41415781d4f9233df58d07"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-8-4a3fd3381297>:41: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2340' max='2340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2340/2340 20:15, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Top-1 accuracy</th>\n","      <th>Bleu score</th>\n","      <th>Bleu precisions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.320600</td>\n","      <td>0.324598</td>\n","      <td>0.033654</td>\n","      <td>0.230745</td>\n","      <td>[0.857055589492975, 0.6627011896431071, 0.4176904176904177, 0.26159921026653504]</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.397600</td>\n","      <td>0.226343</td>\n","      <td>0.028846</td>\n","      <td>0.280199</td>\n","      <td>[0.8923529411764706, 0.7158176943699732, 0.4883177570093458, 0.33271375464684017]</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.301500</td>\n","      <td>0.188934</td>\n","      <td>0.038462</td>\n","      <td>0.307298</td>\n","      <td>[0.8934097421203439, 0.7267404033832141, 0.5139202407825433, 0.3773416592328278]</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.260000</td>\n","      <td>0.167626</td>\n","      <td>0.028846</td>\n","      <td>0.309110</td>\n","      <td>[0.8825503355704698, 0.7037974683544304, 0.49489795918367346, 0.35738831615120276]</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.234800</td>\n","      <td>0.157109</td>\n","      <td>0.052885</td>\n","      <td>0.331374</td>\n","      <td>[0.8946200776483638, 0.7379310344827587, 0.5212689257390051, 0.3994910941475827]</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.217200</td>\n","      <td>0.144740</td>\n","      <td>0.038462</td>\n","      <td>0.331397</td>\n","      <td>[0.8737127371273713, 0.722052535125229, 0.5052484254723583, 0.3726453726453726]</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.204900</td>\n","      <td>0.136386</td>\n","      <td>0.043269</td>\n","      <td>0.325964</td>\n","      <td>[0.876226826608506, 0.7214022140221402, 0.5, 0.3652892561983471]</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.192000</td>\n","      <td>0.131472</td>\n","      <td>0.057692</td>\n","      <td>0.354200</td>\n","      <td>[0.8796592119275826, 0.7371257485029941, 0.5294117647058824, 0.4043062200956938]</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.183100</td>\n","      <td>0.129062</td>\n","      <td>0.052885</td>\n","      <td>0.355570</td>\n","      <td>[0.8804004214963119, 0.7390532544378698, 0.5182186234817814, 0.391679748822606]</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.177800</td>\n","      <td>0.125676</td>\n","      <td>0.052885</td>\n","      <td>0.351565</td>\n","      <td>[0.8830687830687831, 0.7300832342449465, 0.5169606512890095, 0.3886255924170616]</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.171700</td>\n","      <td>0.121948</td>\n","      <td>0.048077</td>\n","      <td>0.350977</td>\n","      <td>[0.8721174004192872, 0.7211764705882353, 0.510053619302949, 0.37850467289719625]</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.164200</td>\n","      <td>0.119639</td>\n","      <td>0.043269</td>\n","      <td>0.338499</td>\n","      <td>[0.8765432098765432, 0.7293051359516616, 0.5093296475466482, 0.37368845843422116]</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.162900</td>\n","      <td>0.118603</td>\n","      <td>0.048077</td>\n","      <td>0.339430</td>\n","      <td>[0.869034994697773, 0.7210965435041716, 0.501360544217687, 0.3629160063391442]</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.161200</td>\n","      <td>0.116495</td>\n","      <td>0.052885</td>\n","      <td>0.342677</td>\n","      <td>[0.8723404255319149, 0.7314593301435407, 0.5102459016393442, 0.37101910828025475]</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.152500</td>\n","      <td>0.113551</td>\n","      <td>0.052885</td>\n","      <td>0.345666</td>\n","      <td>[0.8706758914316126, 0.7307001795332136, 0.5167464114832536, 0.3816733067729084]</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.148700</td>\n","      <td>0.110632</td>\n","      <td>0.052885</td>\n","      <td>0.360865</td>\n","      <td>[0.8627858627858628, 0.7261072261072261, 0.5238726790450928, 0.3930769230769231]</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.145900</td>\n","      <td>0.110594</td>\n","      <td>0.057692</td>\n","      <td>0.348791</td>\n","      <td>[0.8645397489539749, 0.7247652582159625, 0.5060160427807486, 0.3687888198757764]</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.146600</td>\n","      <td>0.110568</td>\n","      <td>0.048077</td>\n","      <td>0.336245</td>\n","      <td>[0.8658922914466737, 0.7158956109134045, 0.4925575101488498, 0.35039370078740156]</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.148600</td>\n","      <td>0.110438</td>\n","      <td>0.052885</td>\n","      <td>0.360063</td>\n","      <td>[0.862015503875969, 0.726693688477128, 0.5161290322580645, 0.38215102974828374]</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.144800</td>\n","      <td>0.109845</td>\n","      <td>0.052885</td>\n","      <td>0.346750</td>\n","      <td>[0.8625, 0.7143691588785047, 0.4973404255319149, 0.36342592592592593]</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.141800</td>\n","      <td>0.109475</td>\n","      <td>0.048077</td>\n","      <td>0.343672</td>\n","      <td>[0.8564076170869789, 0.7014409221902017, 0.48068107400130977, 0.3464746019711903]</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.143800</td>\n","      <td>0.108788</td>\n","      <td>0.052885</td>\n","      <td>0.342693</td>\n","      <td>[0.8619615983393877, 0.7114601512507271, 0.48643282594308407, 0.3484267075978511]</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.141300</td>\n","      <td>0.108193</td>\n","      <td>0.048077</td>\n","      <td>0.344421</td>\n","      <td>[0.8575851393188855, 0.7057803468208093, 0.4868593955321945, 0.34779299847793]</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.857055589492975, 0.6627011896431071, 0.4176904176904177, 0.26159921026653504]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8923529411764706, 0.7158176943699732, 0.4883177570093458, 0.33271375464684017]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8934097421203439, 0.7267404033832141, 0.5139202407825433, 0.3773416592328278]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8825503355704698, 0.7037974683544304, 0.49489795918367346, 0.35738831615120276]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8946200776483638, 0.7379310344827587, 0.5212689257390051, 0.3994910941475827]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.8737127371273713, 0.722052535125229, 0.5052484254723583, 0.3726453726453726]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.876226826608506, 0.7214022140221402, 0.5, 0.3652892561983471]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8796592119275826, 0.7371257485029941, 0.5294117647058824, 0.4043062200956938]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8804004214963119, 0.7390532544378698, 0.5182186234817814, 0.391679748822606]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8830687830687831, 0.7300832342449465, 0.5169606512890095, 0.3886255924170616]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.8721174004192872, 0.7211764705882353, 0.510053619302949, 0.37850467289719625]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8765432098765432, 0.7293051359516616, 0.5093296475466482, 0.37368845843422116]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.869034994697773, 0.7210965435041716, 0.501360544217687, 0.3629160063391442]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8723404255319149, 0.7314593301435407, 0.5102459016393442, 0.37101910828025475]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8706758914316126, 0.7307001795332136, 0.5167464114832536, 0.3816733067729084]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.8627858627858628, 0.7261072261072261, 0.5238726790450928, 0.3930769230769231]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8645397489539749, 0.7247652582159625, 0.5060160427807486, 0.3687888198757764]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8658922914466737, 0.7158956109134045, 0.4925575101488498, 0.35039370078740156]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.862015503875969, 0.726693688477128, 0.5161290322580645, 0.38215102974828374]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8625, 0.7143691588785047, 0.4973404255319149, 0.36342592592592593]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.8564076170869789, 0.7014409221902017, 0.48068107400130977, 0.3464746019711903]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8619615983393877, 0.7114601512507271, 0.48643282594308407, 0.3484267075978511]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"[0.8575851393188855, 0.7057803468208093, 0.4868593955321945, 0.34779299847793]\" of type <class 'list'> for key \"eval/bleu precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["# transfer learning\n","from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","# load realigned dataset\n","dataset = load_dataset('csv', data_files=os.path.join(home_path, data_dir, new_data_filename))\n","train_dataset, test_dataset = dataset['train'].train_test_split(test_size=0.1, shuffle=True, seed=int_seed).values()\n","tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n","tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n","\n","# load pretrained model\n","model = AutoModelForSeq2SeqLM.from_pretrained(input_model_dir)\n","batch_size = 16\n","output_model_name = model_checkpoint.split(\"/\")[-1]+'-'+dataset_name+\"-epoch20-trainpoint\"+str(i+1)\n","output_model_dir = output_model_dir+output_model_name\n","\n","# set trainer params\n","args = Seq2SeqTrainingArguments(\n","    output_model_dir,\n","    output_model_name,\n","    evaluation_strategy = \"steps\",\n","    eval_steps=100,\n","    logging_steps=100,\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    seed=int_seed,\n","    save_total_limit=1,\n","    num_train_epochs=20,\n","    predict_with_generate=True,\n","    fp16=False,\n","    #push_to_hub=True,\n","    #report_to=\"tensorboard\",\n","    #load_best_model_at_end=True,\n","    #save_strategy = \"no\"\n",")\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# instantiate trainer\n","trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_train_dataset ,\n","    eval_dataset=tokenized_test_dataset ,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# run train\n","trainer.train()\n","trainer.save_model()"]},{"cell_type":"markdown","metadata":{"id":"_UeG_yuLYR94"},"source":["The below code block is for testing using the above transfer-learned model or already pre-trained model. If you want to only test without training, then run from the first code block but skip the just previous training code block and run the below code block."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182337,"status":"ok","timestamp":1732447873124,"user":{"displayName":"Jihun Oh","userId":"16459593472256263899"},"user_tz":-540},"id":"2Q79N0RfsNhH","outputId":"01e6cbbc-796c-4983-fcae-c9d030e52822"},"outputs":[{"output_type":"stream","name":"stdout","text":["The test data number = 208\n","Top-1 accuracy = 0.09615384615384616\n","Bleu score = 0.5354062188772656\n","Bleu precision = [0.8618050151685388, 0.7313585529576325, 0.5328485424468097, 0.39822951716585675]\n"]}],"source":["# Test with a transfer learning model\n","import torch\n","import evaluate\n","from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","show_diff_parenthe_results = False\n","output_model_dir = os.path.join(home_path, \"model\", \"t5-base-transfer-learning\", f\"t5-base-{dataset_name}-epoch20-trainpoint2082/checkpoint-2340\")\n","#output_model_dir = os.path.join(home_path, \"model\", \"t5-base-epch20-infix-word-04-21\", \"checkpoint-62500\")\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(output_model_dir).to(device)\n","acc_top1 = 0.\n","acc_bleu_scores = 0.\n","acc_bleu_precisions = [0., 0., 0., 0.]\n","\n","metric = evaluate.load(\"accuracy\")\n","dataset = load_dataset('csv', data_files=os.path.join(home_path, data_dir, new_data_filename))\n","train_dataset, test_dataset = dataset['train'].train_test_split(test_size=0.1).values()\n","tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n","prefix = \"Transform the following sentence into Signal Temporal logic: \"\n","\n","with open(output_model_dir +'/result.txt', 'w') as f_result:\n","    for i in range(len(tokenized_test_dataset)):\n","        input = [prefix + tokenized_test_dataset[i]['sentence']]\n","        f_result.write(\"input: \" + input[0] + '\\n')\n","\n","        input = tokenizer(input, max_length=max_input_length, truncation=True, return_tensors=\"pt\").to(device)\n","        output = model.generate(**input, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","        decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n","        label = tokenized_test_dataset[i]['ltl']\n","        predicted_output = correct_parenthe(decoded_output.strip())\n","        f_result.write(\"label: \" + label + '\\n')\n","        f_result.write(\"pred: \" + predicted_output + '\\n')\n","        f_result.write('\\n')\n","\n","        if predicted_output == label:\n","            acc_top1 += 1\n","\n","        bleu = bleu_metric.compute(predictions=[predicted_output], references=[label])\n","        acc_bleu_scores += bleu['bleu']\n","        acc_bleu_precisions = [acc_bleu_precisions[n] + j for n, j in enumerate(bleu['precisions'])]\n","\n","    test_data_num = i + 1\n","    acc_top1 /= test_data_num\n","    acc_bleu_scores /= test_data_num\n","    acc_bleu_precisions = [j / test_data_num for j in acc_bleu_precisions]\n","\n","    print(f\"The test data number = {test_data_num}\")\n","    print(f\"Top-1 accuracy = {acc_top1}\")\n","    print(f\"Bleu score = {acc_bleu_scores}\")\n","    print(f\"Bleu precision = {acc_bleu_precisions}\")\n","    f_result.write('\\n')\n","    f_result.write(f\"The test data number = {test_data_num}\\n\")\n","    f_result.write(f\"Top-1 accuracy = {acc_top1}\\n\")\n","    f_result.write(f\"Bleu score = {acc_bleu_scores}\\n\")\n","    f_result.write(f\"Bleu precision = {acc_bleu_precisions}\\n\")\n","\n","f_result.close()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPK+xOoDx9aYjTfBvWEtrNK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d033103e85e3471fba23e9a9cf5b179e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c061efea6b047898f6931781b9aeedf","IPY_MODEL_e249614be7cb4ed1bbb13e41e70d05de","IPY_MODEL_75d73ad5f38e4c3cb7d5970fc2f17f34"],"layout":"IPY_MODEL_40a95f147e0f4be093bdb7d710fadbd1"}},"5c061efea6b047898f6931781b9aeedf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5df7c5d7c954fc49a23008e024ca20b","placeholder":"​","style":"IPY_MODEL_6b1cb18980b943e6acb4ab794c3f6318","value":"Downloading builder script: 100%"}},"e249614be7cb4ed1bbb13e41e70d05de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_769791cd621a492ab808711536e8e0f1","max":5937,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cb25a830a7b4fe1ae6cb25a76de32c9","value":5937}},"75d73ad5f38e4c3cb7d5970fc2f17f34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e42072e5f284e998d29089d75c1ac0a","placeholder":"​","style":"IPY_MODEL_8a4e89fa1122441d8677422c7c41d1f8","value":" 5.94k/5.94k [00:00&lt;00:00, 495kB/s]"}},"40a95f147e0f4be093bdb7d710fadbd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5df7c5d7c954fc49a23008e024ca20b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b1cb18980b943e6acb4ab794c3f6318":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"769791cd621a492ab808711536e8e0f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cb25a830a7b4fe1ae6cb25a76de32c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e42072e5f284e998d29089d75c1ac0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a4e89fa1122441d8677422c7c41d1f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"862cda28d31844f9bf38be758a714faa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5fd87dc614f4ceead7073d9657541ed","IPY_MODEL_3cc0979deafb42ec9040322bf73e2949","IPY_MODEL_ce5dfc9b71584791920a466353ff4b0d"],"layout":"IPY_MODEL_fb89dc78b8a94f65b81a4d68d3df060e"}},"d5fd87dc614f4ceead7073d9657541ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b540cc15830f48a68ad99f56bae86e94","placeholder":"​","style":"IPY_MODEL_4bcb4bd9728643e2874a9618e3710f23","value":"Downloading extra modules: "}},"3cc0979deafb42ec9040322bf73e2949":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_664c94ce75f94b2788f4760110c617f4","max":1554,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84de81bdfcb443c496cfff3fa00ca4ee","value":1554}},"ce5dfc9b71584791920a466353ff4b0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_349112816f9945deaae49a27c8e2b293","placeholder":"​","style":"IPY_MODEL_de69b594557a4968b47b7d00761c1db9","value":" 4.07k/? [00:00&lt;00:00, 316kB/s]"}},"fb89dc78b8a94f65b81a4d68d3df060e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b540cc15830f48a68ad99f56bae86e94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bcb4bd9728643e2874a9618e3710f23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"664c94ce75f94b2788f4760110c617f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84de81bdfcb443c496cfff3fa00ca4ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"349112816f9945deaae49a27c8e2b293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de69b594557a4968b47b7d00761c1db9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e020babe48d45f39a4350341521ed53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf24b16d4fde49a8bff7642b1462c15e","IPY_MODEL_ac1d77834f4c4583a98c2b4797cd54f6","IPY_MODEL_492580da9fb54ad088e670598f4cb4a2"],"layout":"IPY_MODEL_8d01078294694f7395feea9a1a7d7cdd"}},"cf24b16d4fde49a8bff7642b1462c15e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22fd138d7ba8407fbe8db57e3bfd5513","placeholder":"​","style":"IPY_MODEL_e27690fdacf141fe9e674f7065e90aa5","value":"Downloading extra modules: 100%"}},"ac1d77834f4c4583a98c2b4797cd54f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_266b92d1da8747709735b9f1f3d07bbe","max":3344,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbdd10b2bc73463d8cfac83ffb084da2","value":3344}},"492580da9fb54ad088e670598f4cb4a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3095935ce58c489f836b43be6c6ce6ba","placeholder":"​","style":"IPY_MODEL_40a0098398694ffaa8cc6b417ea0ffe9","value":" 3.34k/3.34k [00:00&lt;00:00, 285kB/s]"}},"8d01078294694f7395feea9a1a7d7cdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22fd138d7ba8407fbe8db57e3bfd5513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e27690fdacf141fe9e674f7065e90aa5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"266b92d1da8747709735b9f1f3d07bbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbdd10b2bc73463d8cfac83ffb084da2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3095935ce58c489f836b43be6c6ce6ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40a0098398694ffaa8cc6b417ea0ffe9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c298f50562d4c38ab287b02cbf002d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_576c26e73f4c4e9781b637ecc2c57019","IPY_MODEL_d383be59f5374e7aaf15748220d913e6","IPY_MODEL_27d1074151fe48038efbe62718bda78c"],"layout":"IPY_MODEL_548a28cf358d4b4998ab1e0864410e1b"}},"576c26e73f4c4e9781b637ecc2c57019":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39ee03521db0459aaefd3f9b78808d2c","placeholder":"​","style":"IPY_MODEL_7167c31aba1544adace00ab9296dc9bd","value":"Map: 100%"}},"d383be59f5374e7aaf15748220d913e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c07d1c8b91a34b89ac5da66bd7f07dfd","max":1872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9db5829ff51494cb489124ba8fb8457","value":1872}},"27d1074151fe48038efbe62718bda78c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1408aac59cc54428a8273ac15046759b","placeholder":"​","style":"IPY_MODEL_b75bed6e93b14801abc9dde849664d7a","value":" 1872/1872 [00:00&lt;00:00, 13025.36 examples/s]"}},"548a28cf358d4b4998ab1e0864410e1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39ee03521db0459aaefd3f9b78808d2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7167c31aba1544adace00ab9296dc9bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c07d1c8b91a34b89ac5da66bd7f07dfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9db5829ff51494cb489124ba8fb8457":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1408aac59cc54428a8273ac15046759b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b75bed6e93b14801abc9dde849664d7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d382c55a8d41415781d4f9233df58d07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_195f425ae5ac40b0bcfdf776966ec432","IPY_MODEL_6e79fc3bd54349c8a851001799f421fa","IPY_MODEL_297c3eed091845c09eabf2c47db3c12a"],"layout":"IPY_MODEL_24653031bda54937b249883fe1d46281"}},"195f425ae5ac40b0bcfdf776966ec432":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee8f25e152847e795600bcd61ab94af","placeholder":"​","style":"IPY_MODEL_8fffaba9808c43c384cd1e3577c68005","value":"Map: 100%"}},"6e79fc3bd54349c8a851001799f421fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad1af20536084184874b1211ef57fd22","max":208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f98c6fd46c9147a4a0f1e94b1a75efbd","value":208}},"297c3eed091845c09eabf2c47db3c12a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d7ffe69833b46a9a1e04188eb7ae0c9","placeholder":"​","style":"IPY_MODEL_9c999c7623f54164a63d474c7346c360","value":" 208/208 [00:00&lt;00:00, 6071.97 examples/s]"}},"24653031bda54937b249883fe1d46281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee8f25e152847e795600bcd61ab94af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fffaba9808c43c384cd1e3577c68005":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad1af20536084184874b1211ef57fd22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f98c6fd46c9147a4a0f1e94b1a75efbd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d7ffe69833b46a9a1e04188eb7ae0c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c999c7623f54164a63d474c7346c360":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}