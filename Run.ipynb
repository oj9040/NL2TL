{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Ag-SlDfZNAtNqPD3lgW061Lqo_4q8qYx","authorship_tag":"ABX9TyMLNfG4Iyffzvh1MHai0eCj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"a7073bb154594b599b4bf5f2c45bbe94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdb054fdf5744b7496c7a2086b8564f4","IPY_MODEL_b9a139146e7e4a738a706ea74dfb1824","IPY_MODEL_eeee13f9e82b4beebdfd6cf550550abb"],"layout":"IPY_MODEL_f9866b814d8642bf94cff1b33b0c8218"}},"bdb054fdf5744b7496c7a2086b8564f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a507451c0964c398d8ecf46f2ab9ca4","placeholder":"​","style":"IPY_MODEL_3d2b1863376548cb9340ae648c22d94d","value":"Downloading: 100%"}},"b9a139146e7e4a738a706ea74dfb1824":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f86a825f66264c4984a1894bfd137e7b","max":666,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e70878e25ae4a8986cdef1d88328dcd","value":666}},"eeee13f9e82b4beebdfd6cf550550abb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55cc919710804d05b92528301bc305b3","placeholder":"​","style":"IPY_MODEL_85e2d0299d534d4496ce442b975d9fe4","value":" 666/666 [00:00&lt;00:00, 26.0kB/s]"}},"f9866b814d8642bf94cff1b33b0c8218":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a507451c0964c398d8ecf46f2ab9ca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d2b1863376548cb9340ae648c22d94d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f86a825f66264c4984a1894bfd137e7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e70878e25ae4a8986cdef1d88328dcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"55cc919710804d05b92528301bc305b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85e2d0299d534d4496ce442b975d9fe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"998158efd6d744de956989b5bc1f7336":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85483abc22824585a8ebab1df715841f","IPY_MODEL_d1c7c11a488d4924a04f7e9bd33fc49e","IPY_MODEL_91cacb018c15492ea761be1dcca12987"],"layout":"IPY_MODEL_0ca1572ec3a24ec382d34dc287457465"}},"85483abc22824585a8ebab1df715841f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46b400427a6f4e72a5112f63bfb58484","placeholder":"​","style":"IPY_MODEL_e97c99758eef4510a60e1f50283f2411","value":"Downloading: 100%"}},"d1c7c11a488d4924a04f7e9bd33fc49e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0d75ac0df5d4a7294aa405e1ab11274","max":3247202234,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff1ff495635f4707b8d176b8646f8ff2","value":3247202234}},"91cacb018c15492ea761be1dcca12987":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c904d6fb34f4821ab7eda09d882dcc2","placeholder":"​","style":"IPY_MODEL_8d7b8340a3414275a0a61a365d1f42f5","value":" 3.25G/3.25G [00:50&lt;00:00, 82.5MB/s]"}},"0ca1572ec3a24ec382d34dc287457465":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b400427a6f4e72a5112f63bfb58484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e97c99758eef4510a60e1f50283f2411":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0d75ac0df5d4a7294aa405e1ab11274":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff1ff495635f4707b8d176b8646f8ff2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c904d6fb34f4821ab7eda09d882dcc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d7b8340a3414275a0a61a365d1f42f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e59c23b62a54b57828457c1550c6640":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9d5a245241a428d809e154a9275e289","IPY_MODEL_d03c9991fc7443bfa86c2cffee1f0a62","IPY_MODEL_b3dbf8226a0a4d9289cb8e5504f30b58"],"layout":"IPY_MODEL_3714b8ce7ed14bdc89ece7138340b2d8"}},"c9d5a245241a428d809e154a9275e289":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79196cb0460845c5829ccdc4b19ba94f","placeholder":"​","style":"IPY_MODEL_b36856a23816431d83af44997c014073","value":"Downloading: 100%"}},"d03c9991fc7443bfa86c2cffee1f0a62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28c876d0662a4d59bbecbc2b527f5351","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03e1119063504706bfb0d94f0cded95e","value":1042301}},"b3dbf8226a0a4d9289cb8e5504f30b58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fe66c601517469d94bb6008032e9782","placeholder":"​","style":"IPY_MODEL_2e583b7d29404959b69a35da69e37713","value":" 1.04M/1.04M [00:00&lt;00:00, 1.84MB/s]"}},"3714b8ce7ed14bdc89ece7138340b2d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79196cb0460845c5829ccdc4b19ba94f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b36856a23816431d83af44997c014073":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c876d0662a4d59bbecbc2b527f5351":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03e1119063504706bfb0d94f0cded95e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fe66c601517469d94bb6008032e9782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e583b7d29404959b69a35da69e37713":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7785f59865684698805cde877281aa55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_255623340a24437c897eeab0a70686bf","IPY_MODEL_4c9b6577125e4ebc9429d25cc9252c25","IPY_MODEL_6d24b901581a4dc28116cba9f0f8b1c7"],"layout":"IPY_MODEL_9a4ba699756b444e96929a42ad9bcd29"}},"255623340a24437c897eeab0a70686bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b82f09988bb6410b852f2e499f35918f","placeholder":"​","style":"IPY_MODEL_56ffa74c8bf94db3be41db2a500d6883","value":"Downloading: 100%"}},"4c9b6577125e4ebc9429d25cc9252c25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a909f44c143b445c99bdf19973022174","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15f87c5c8d1740debb57f5fbe0261ae6","value":456318}},"6d24b901581a4dc28116cba9f0f8b1c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e088e072967c4182b1296906699dcc7b","placeholder":"​","style":"IPY_MODEL_9eb8a89be3424edbb9e2358ef1b000d4","value":" 456k/456k [00:00&lt;00:00, 676kB/s]"}},"9a4ba699756b444e96929a42ad9bcd29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b82f09988bb6410b852f2e499f35918f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56ffa74c8bf94db3be41db2a500d6883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a909f44c143b445c99bdf19973022174":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15f87c5c8d1740debb57f5fbe0261ae6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e088e072967c4182b1296906699dcc7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb8a89be3424edbb9e2358ef1b000d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24948fe2726b4ae8b3860ef7df6fb98a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc67184b186042fcbaa7297d52486758","IPY_MODEL_2aa46704c15c4a379c5026713c136f56","IPY_MODEL_a2eac32a837d4adea48c084e0d9d0bd2"],"layout":"IPY_MODEL_28a5a42e17514b4e979ad0d65a4bc158"}},"cc67184b186042fcbaa7297d52486758":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a2b0c342bc14cf4b15b3c3dd7405abd","placeholder":"​","style":"IPY_MODEL_502b40397b2647dfa0e0ce0a240431f9","value":"Downloading: 100%"}},"2aa46704c15c4a379c5026713c136f56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5ef2e0715944929bfa9014bd9c20db","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2918ac6da9d648799c2ad235c6cc1d04","value":1355256}},"a2eac32a837d4adea48c084e0d9d0bd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3785b276ccd14c849471c405b364b01a","placeholder":"​","style":"IPY_MODEL_a67c5a0efade45ae98cc69063a24eb1d","value":" 1.36M/1.36M [00:00&lt;00:00, 1.97MB/s]"}},"28a5a42e17514b4e979ad0d65a4bc158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a2b0c342bc14cf4b15b3c3dd7405abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"502b40397b2647dfa0e0ce0a240431f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b5ef2e0715944929bfa9014bd9c20db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2918ac6da9d648799c2ad235c6cc1d04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3785b276ccd14c849471c405b364b01a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a67c5a0efade45ae98cc69063a24eb1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["### Enter your path for downloaded directory NL2STL\n","home_path_nl2stl = 'YOUR-OWN-PATH/NL2STL'\n","%cd 'YOUR-OWN-PATH/NL2STL'\n","\n","#home_path_nl2stl = '/content/drive/MyDrive/Colab Notebooks/Code/NLP_robotics/LTL_dataset/github' ### Enter your path for downloaded directory NL2STL\n","#%cd '/content/drive/MyDrive/Colab Notebooks/Code/NLP_robotics/LTL_dataset/github'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcXKBYa4c2Sf","executionInfo":{"status":"ok","timestamp":1669948437813,"user_tz":300,"elapsed":2188,"user":{"displayName":"Yongchao Chen","userId":"06121221447580717190"}},"outputId":"4cbad91a-b7d3-430c-cfac-f15a2b4e6195"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Code/NLP_robotics/LTL_dataset/github\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install SentencePiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qc4ixRSfmiqf","executionInfo":{"status":"ok","timestamp":1669948456430,"user_tz":300,"elapsed":18621,"user":{"displayName":"Yongchao Chen","userId":"06121221447580717190"}},"outputId":"62003472-d5ac-4c91-a361-d28d15017e83"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 15.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 64.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 57.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting SentencePiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 1.6 MB/s \n","\u001b[?25hInstalling collected packages: SentencePiece\n","Successfully installed SentencePiece-0.1.97\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import time\n","from argparse import ArgumentParser\n","import tqdm\n","import torch\n","import torch.nn as nn\n","\n","from torch.utils.data import DataLoader\n","\n","from transformers import T5Tokenizer, AdamW, get_linear_schedule_with_warmup\n","from seq2seq import LTL2Eng\n","from data import LTLDataset, generate_vocabs, LTL2EngT5Dataset, UnlabeledLTLDataset\n","from config import Config\n","from util import collect_ltl_vocabs\n","\n","config = Config.from_json_file('eng2ltl_t5_load_data.json')\n","input_dir = os.path.join(home_path_nl2stl, 'eng2ltl_para_gen_5_11_28_word_infix')\n","\n","torch.cuda.set_device(0)\n","model_name = config.bert_model_name\n","tokenizer = T5Tokenizer.from_pretrained(model_name,cache_dir=config.bert_cache_dir)\n","\n","ltl_vocabs = collect_ltl_vocabs([home_path_nl2stl+config.train_file,home_path_nl2stl+config.dev_file,home_path_nl2stl+config.test_file])\n","model = LTL2Eng(config,ltl_vocabs,tokenizer)\n","model.load_state_dict(torch.load(input_dir+'/model_state.pt'))\n","model.cuda(device=0)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a7073bb154594b599b4bf5f2c45bbe94","bdb054fdf5744b7496c7a2086b8564f4","b9a139146e7e4a738a706ea74dfb1824","eeee13f9e82b4beebdfd6cf550550abb","f9866b814d8642bf94cff1b33b0c8218","8a507451c0964c398d8ecf46f2ab9ca4","3d2b1863376548cb9340ae648c22d94d","f86a825f66264c4984a1894bfd137e7b","1e70878e25ae4a8986cdef1d88328dcd","55cc919710804d05b92528301bc305b3","85e2d0299d534d4496ce442b975d9fe4","998158efd6d744de956989b5bc1f7336","85483abc22824585a8ebab1df715841f","d1c7c11a488d4924a04f7e9bd33fc49e","91cacb018c15492ea761be1dcca12987","0ca1572ec3a24ec382d34dc287457465","46b400427a6f4e72a5112f63bfb58484","e97c99758eef4510a60e1f50283f2411","e0d75ac0df5d4a7294aa405e1ab11274","ff1ff495635f4707b8d176b8646f8ff2","0c904d6fb34f4821ab7eda09d882dcc2","8d7b8340a3414275a0a61a365d1f42f5","1e59c23b62a54b57828457c1550c6640","c9d5a245241a428d809e154a9275e289","d03c9991fc7443bfa86c2cffee1f0a62","b3dbf8226a0a4d9289cb8e5504f30b58","3714b8ce7ed14bdc89ece7138340b2d8","79196cb0460845c5829ccdc4b19ba94f","b36856a23816431d83af44997c014073","28c876d0662a4d59bbecbc2b527f5351","03e1119063504706bfb0d94f0cded95e","2fe66c601517469d94bb6008032e9782","2e583b7d29404959b69a35da69e37713","7785f59865684698805cde877281aa55","255623340a24437c897eeab0a70686bf","4c9b6577125e4ebc9429d25cc9252c25","6d24b901581a4dc28116cba9f0f8b1c7","9a4ba699756b444e96929a42ad9bcd29","b82f09988bb6410b852f2e499f35918f","56ffa74c8bf94db3be41db2a500d6883","a909f44c143b445c99bdf19973022174","15f87c5c8d1740debb57f5fbe0261ae6","e088e072967c4182b1296906699dcc7b","9eb8a89be3424edbb9e2358ef1b000d4","24948fe2726b4ae8b3860ef7df6fb98a","cc67184b186042fcbaa7297d52486758","2aa46704c15c4a379c5026713c136f56","a2eac32a837d4adea48c084e0d9d0bd2","28a5a42e17514b4e979ad0d65a4bc158","4a2b0c342bc14cf4b15b3c3dd7405abd","502b40397b2647dfa0e0ce0a240431f9","9b5ef2e0715944929bfa9014bd9c20db","2918ac6da9d648799c2ad235c6cc1d04","3785b276ccd14c849471c405b364b01a","a67c5a0efade45ae98cc69063a24eb1d"]},"id":"2PcUg4mVzLGO","executionInfo":{"status":"ok","timestamp":1669949569165,"user_tz":300,"elapsed":172586,"user":{"displayName":"Yongchao Chen","userId":"06121221447580717190"}},"outputId":"5f60eebd-7f7e-4efd-b4e4-cb11aaf5fe4a"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7073bb154594b599b4bf5f2c45bbe94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998158efd6d744de956989b5bc1f7336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e59c23b62a54b57828457c1550c6640"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7785f59865684698805cde877281aa55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24948fe2726b4ae8b3860ef7df6fb98a"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["LTL2Eng(\n","  (ltl2eng): T5ForConditionalGeneration(\n","    (shared): Embedding(32128, 768)\n","    (encoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 768)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","                (relative_attention_bias): Embedding(32, 12)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (2): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (3): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (4): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (5): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (6): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (7): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (8): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (9): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (10): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (11): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (decoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 768)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","                (relative_attention_bias): Embedding(32, 12)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (2): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (3): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (4): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (5): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (6): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (7): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (8): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (9): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (10): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (11): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n","  )\n","  (eng2ltl): T5ForConditionalGeneration(\n","    (shared): Embedding(32128, 768)\n","    (encoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 768)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","                (relative_attention_bias): Embedding(32, 12)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (2): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (3): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (4): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (5): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (6): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (7): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (8): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (9): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (10): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (11): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (decoder): T5Stack(\n","      (embed_tokens): Embedding(32128, 768)\n","      (block): ModuleList(\n","        (0): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","                (relative_attention_bias): Embedding(32, 12)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (1): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (2): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (3): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (4): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (5): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (6): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (7): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (8): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (9): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (10): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (11): T5Block(\n","          (layer): ModuleList(\n","            (0): T5LayerSelfAttention(\n","              (SelfAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (1): T5LayerCrossAttention(\n","              (EncDecAttention): T5Attention(\n","                (q): Linear(in_features=768, out_features=768, bias=False)\n","                (k): Linear(in_features=768, out_features=768, bias=False)\n","                (v): Linear(in_features=768, out_features=768, bias=False)\n","                (o): Linear(in_features=768, out_features=768, bias=False)\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (2): T5LayerFF(\n","              (DenseReluDense): T5DenseGatedActDense(\n","                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","                (wo): Linear(in_features=2048, out_features=768, bias=False)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","                (act): NewGELUActivation()\n","              )\n","              (layer_norm): T5LayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (final_layer_norm): T5LayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n","  )\n","  (gpt2): GPT2LMHeadModel(\n","    (transformer): GPT2Model(\n","      (wte): Embedding(50257, 1280)\n","      (wpe): Embedding(1024, 1280)\n","      (drop): Dropout(p=0.1, inplace=False)\n","      (h): ModuleList(\n","        (0): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (24): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (25): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (26): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (27): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (28): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (29): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (30): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (31): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (32): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (33): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (34): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (35): GPT2Block(\n","          (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (attn): GPT2Attention(\n","            (c_attn): Conv1D()\n","            (c_proj): Conv1D()\n","            (attn_dropout): Dropout(p=0.1, inplace=False)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","          (mlp): GPT2MLP(\n","            (c_fc): Conv1D()\n","            (c_proj): Conv1D()\n","            (act): NewGELUActivation()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n","  )\n","  (ce_loss_fct): CrossEntropyLoss()\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["config = Config.from_json_file('eng2ltl_t5_load_data.json')\n","config.train_file"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"ew99sBKZunf7","executionInfo":{"status":"ok","timestamp":1669949578389,"user_tz":300,"elapsed":530,"user":{"displayName":"Yongchao Chen","userId":"06121221447580717190"}},"outputId":"ecb6134c-7833-4bd2-a2bd-a31eb73de878"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/Data_para_gen_5_11_28_word_infix/combine_train_seq2tree_idea4.jsonl'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import pandas as pd\n","# Here you can define the imperative natural sentences to express orders, like the following example\n","# Here we represent atomic propositions with ( prop_* )\n","\n","test_sentence = ['If ( prop_4 ) happens and implies ( prop_2 ) and this scenario continues to hold until at some point during the 243 to 582 time units ( prop_3 ) is detected , then the scenario is equivalent to ( prop_1 ) .',\n","                 'If it is not the case that ( prop_3 ) is detected for each time instant in the coming 164 to 612 time units , or else ( prop_1 ) happens , then ( prop_2 ) .',\n","                 'If at some point ( prop_3 ) and ( prop_2 ) , and is equivalent to ( prop_4 ) , and this scenario will hold until at some other point ( prop_1 ) is detected .',                 \n","                 \n","                 ]\n","\n","'''\n","# Another way is to load the excel files, there are some example files in the dataset dir\n","file_name = '/output_davinci_gen_ltl_long_8'\n","df = pd.read_excel(home_path_nl2stl+'/dataset/'+file_name+'.xlsx')\n","test_sentence = [df['paraphrased_logic_sentence'][i] for i in range(len(df))]\n","'''\n"],"metadata":{"id":"Yg3VCOqNkRxv","executionInfo":{"status":"ok","timestamp":1669949581833,"user_tz":300,"elapsed":547,"user":{"displayName":"Yongchao Chen","userId":"06121221447580717190"}},"colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"30b46c5d-decf-4a06-e75c-f4d1b2edf397"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# Another way is to load the excel files, there are some example files in the dataset dir\\nfile_name = '/output_davinci_gen_ltl_long_8'\\ndf = pd.read_excel(home_path_nl2stl+'/dataset/'+file_name+'.xlsx')\\ntest_sentence = [df['paraphrased_logic_sentence'][i] for i in range(len(df))]\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["import os\n","home_path_output = home_path_nl2stl + '/application_test/'\n","if not os.path.exists(home_path_output):\n","  os.mkdir(home_path_output)\n","\n","dataset_total = [];\n","with open(home_path_output+\"test1_word_infix.jsonl\", \"w\") as outfile:\n","    for i in range(len(test_sentence)):\n","      dataset_item = {};\n","      dataset_item['id'] = i\n","      dataset_item['logic_ltl'] = ''\n","      dataset_item['logic_sentence'] = test_sentence[i].split(' ')\n","      outfile.write(json.dumps(dataset_item)+'\\n')\n","outfile.close()\n","\n","test_set = LTL2EngT5Dataset(home_path_output+\"test1_word_infix.jsonl\",tokenizer,config,model.ltl2eng.config,ltl_vocabs=ltl_vocabs)\n","data_batch =  DataLoader(test_set, batch_size=1,\n","                        shuffle=False, collate_fn=test_set.collate_fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImC_9EEFbS83","executionInfo":{"status":"ok","timestamp":1669949586746,"user_tz":300,"elapsed":813,"user":{"displayName":"Yongchao Chen","userId":"06121221447580717190"}},"outputId":"09887e7b-51c0-4762-927f-203441b9eaf0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["3it [00:00, 290.41it/s]"]},{"output_type":"stream","name":"stdout","text":["Loaded 3 instances from /content/drive/MyDrive/Colab Notebooks/Code/NLP_robotics/LTL_dataset/github/application_test/test1_word_infix.jsonl\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["for i, batch in enumerate(data_batch):\n","  if i <len(test_sentence):\n","    outputs = model.predict_eng2ltl(batch, max_length=config.max_generate_length)\n","    pred_ltls = tokenizer.batch_decode(outputs['output_idxs'], skip_special_tokens=True)\n","    print(test_sentence[i])\n","    print(pred_ltls)\n","    print('\\n')\n","  else:\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2DP5wIvYnVq","executionInfo":{"status":"ok","timestamp":1669949596833,"user_tz":300,"elapsed":4604,"user":{"displayName":"Yongchao Chen","userId":"06121221447580717190"}},"outputId":"ac1cc9f5-0285-437a-96fa-cf92fa1eeb84"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["If ( prop_4 ) happens and implies ( prop_2 ) and this scenario continues to hold until at some point during the 243 to 582 time units ( prop_3 ) is detected , then the scenario is equivalent to ( prop_1 ) .\n","['( ( ( prop_4 imply prop_2 ) until [243,582] prop_3 ) equal prop_1 )']\n","\n","\n","If it is not the case that ( prop_3 ) is detected for each time instant in the coming 164 to 612 time units , or else ( prop_1 ) happens , then ( prop_2 ) .\n","['( ( negation prop_3 imply prop_1 ) or prop_2 )']\n","\n","\n","If at some point ( prop_3 ) and ( prop_2 ) , and is equivalent to ( prop_4 ) , and this scenario will hold until at some other point ( prop_1 ) is detected .\n","['( ( ( prop_3 and prop_2 ) equal prop_4 ) until prop_1 )']\n","\n","\n"]}]}]}